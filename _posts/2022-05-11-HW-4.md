---
layout: post
title: Fake News Classification
---

In this blog post, I'll demonstrate how to perform NLP with TensorFlow. In particular, we'll be classifying fake news using the Keras functional API and embedding layers. We'll begin by importing necessary packages.


```python
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
import re
import string

from tensorflow.keras import layers, losses, utils
from tensorflow import keras

from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup
```

## Acquire Training Data

We'll read in and examine our data. We have a data frame with title, text, and fake columns; title gives the title of an article, text gives the text of an article, and fake gives 0 if the article is true and 1 if the article contains fake news, as determined by the data collectors.


```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
df = pd.read_csv(train_url)
```


```python
df.head(10)
```





  <div id="df-50ac55cf-b030-4027-90c6-84a239a944ae">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17366</td>
      <td>Merkel: Strong result for Austria's FPO 'big c...</td>
      <td>German Chancellor Angela Merkel said on Monday...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5634</td>
      <td>Trump says Pence will lead voter fraud panel</td>
      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17487</td>
      <td>JUST IN: SUSPECTED LEAKER and â€œClose Confidant...</td>
      <td>On December 5, 2017, Circa s Sara Carter warne...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12217</td>
      <td>Thyssenkrupp has offered help to Argentina ove...</td>
      <td>Germany s Thyssenkrupp, has offered assistance...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5535</td>
      <td>Trump say appeals court decision on travel ban...</td>
      <td>President Donald Trump on Thursday called the ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>13616</td>
      <td>North Korea says successfully launches new ICB...</td>
      <td>North Korea successfully launched a new type o...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1707</td>
      <td>California lawmakers take anti-Trump stance as...</td>
      <td>SACRAMENTO, Calif.California lawmakers voted t...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>15299</td>
      <td>New Delhi declares emergency as toxic smog thi...</td>
      <td>NEW The Indian capital declared a pollution em...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>4049</td>
      <td>AUDIO: Hannity Has RACIST Meltdown, Wants To ...</td>
      <td>Nobody would have ever said this about any of ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>12166</td>
      <td>Forgetful ministers keep Mugabe's name alive a...</td>
      <td>Zimbabwe s Robert Mugabe may have been deposed...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-50ac55cf-b030-4027-90c6-84a239a944ae')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-50ac55cf-b030-4027-90c6-84a239a944ae button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-50ac55cf-b030-4027-90c6-84a239a944ae');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




## Make a Dataset

We'll clean and transform our dataframe into a TensorFlow Dataset. This means removing stopwords, or common terms that won't contribute to the model's learning. This requires downloading and importing `stopwords` from `nltk`, or Natural Language ToolKit. The stopwords are displayed below.


```python
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

stops = set(stopwords.words('english'))
print(stops)
```

    [nltk_data] Downloading package stopwords to /root/nltk_data...
    [nltk_data]   Unzipping corpora/stopwords.zip.
    {'those', 'be', 'yours', "shan't", "didn't", 'ourselves', 'but', "doesn't", 'further', 'ain', 'yourself', 'and', 'some', 'any', 'our', 'he', 'who', 'themselves', 'that', 'so', 'very', "weren't", 've', 'more', "haven't", 'hadn', 'itself', 'into', 'does', "you've", 'you', 'had', 'because', 'hasn', 'out', 'down', 'below', "mightn't", 'we', 'after', 'all', 'her', 'an', 'can', 'should', 're', 'shouldn', 'both', 'again', "couldn't", 'over', 'in', 'under', 'theirs', 'until', 'up', 'when', 'mightn', 'she', 'these', 'was', 'how', 'will', 'wouldn', 'its', 'my', 'there', 'doesn', 'where', 'i', 'their', 'other', 'll', 'him', 'why', "that'll", 'such', 'won', 'haven', 'your', 'the', 'this', 'before', 'about', 'only', 'own', 'if', 'having', "she's", 'whom', 'then', 'by', 'for', 'against', 'no', 'is', 'here', 'm', 'couldn', 'ma', 'each', "hadn't", 'at', 'myself', 'am', 'aren', "won't", "you'd", 'shan', "you'll", 'of', "wasn't", 'while', 'd', 'as', 'nor', 'from', "don't", 'hers', 'has', 'not', 'do', 'doing', 'between', 'yourselves', 'on', 'have', 'which', 'same', 'weren', 'y', 'don', 'needn', 'they', 'are', 'off', 'o', 's', "you're", 'few', 'what', 'his', 'were', "mustn't", 'most', "it's", 'them', 'during', 'or', 'it', "shouldn't", "should've", 'a', "hasn't", 'to', 'being', 'me', 'through', 'did', 'mustn', "aren't", 'himself', 'just', 'wasn', 'too', "wouldn't", "isn't", 'been', 'than', 't', 'herself', 'above', "needn't", 'didn', 'with', 'ours', 'now', 'isn', 'once'}


Next, we define a function that removes the stopwords found in the list above from every entry's title and text column. This uses a concise function that can be found [here](https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe){:target="_blank"}. We also use the `from_tensor_slices()` function to create our dataset.


```python
def make_dataset(df):
  df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stops)]))
  df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stops)]))

  data = tf.data.Dataset.from_tensor_slices(
    ({"title": df[["title"]], # insert "title" and "text" columns as inputs in the dataset
      "text": df[["text"]]},  # use double brackets to preserve dataframe structure
     {"fake": df[["fake"]]})  # insert "fake" column as output in the dataset
  )
  data.batch(100) # batch data by every 100 samples to speed up training

  return data
```


```python
data = make_dataset(df) # apply the function to our dataframe
```

### Validation Data

We'll shuffle our data (which is optional, because the order is already randomized), and split our data so that 80% is used for training and 20% is used for validation.


```python
data = data.shuffle(buffer_size = len(data))

# set the size of the training data to be 80% of the dataset
train_size = int(0.8*len(data))

# take the first 80% of the dataset and assign it to the training set
train = data.take(train_size)
# skip the first 80% of the dataset (take the last 20%) and assign it to the validation set
val = data.skip(train_size)
```


```python
len(train), len(val)
```




    (17959, 4490)



### Base Rate

We'll examine the frequency of the labels in the training data. We can use the `as_numpy_iterator()` function to iterate through the dataset. Use `unbatch()` to remove the batched shape of the dataset.


```python
labels_iterator = train.unbatch().map(lambda input, label: label).as_numpy_iterator()
```


```python
# initialize counts to be 0
real = 0 
fake = 0

# iterate through each element of the set and count the number of real and fake articles
for label in labels_iterator:
  if label["fake"] == 0:
    real += 1
  else:
    fake += 1

print(real, fake)
```

    8571 9388


The baseline model would always guess the most frequent label, which is "fake" in this case. So, it would be correct about 9388/17959 = 52% of the time.

### TextVectorization

Before building our models, we'll need a layer that accepts the text data and converts it into numbers on which computations can be done. We'll first define a `standardization()` function that turns text into lowercase and removes punctuation.


```python
def standardization(input_data):
    # use strings.lower() to turn input lowercase
    lowercase = tf.strings.lower(input_data)
    
    # use strings.regex_replace to remove punctuation.
    no_punctuation = tf.strings.regex_replace(lowercase,
                                  '[%s]' % re.escape(string.punctuation),'')
    # this function's second argument accepts a regex pattern, and 
    # replaces each pattern match in the first argument with the 
    # third argument, the empty string. The second argument uses 
    # re.escape(string.punctuation) to get every punctuation mark into
    # a regex-interpretable format.
    return no_punctuation 
```

We will use this function to create two layers that will be used to initiate data from the title and text columns.


```python
# size of the model's vocabulary; will be used in embedding and visualization later
size_vocabulary = 2000


title_vectorize_layer = TextVectorization(
    standardize = standardization, # perform this cleaning before transforming
    max_tokens = size_vocabulary, # only consider this many words
    output_mode = 'int', # rank each word in the dataset by frequency
    output_sequence_length = 25) # limit number of words in each title sample

# apply this layer to only the "title" input of each data point in the dataset
title_vectorize_layer.adapt(train.map(lambda x, y: x["title"]))

# similar as above, for text
text_vectorize_layer = TextVectorization(
    standardize = standardization,
    max_tokens = size_vocabulary,
    output_mode = 'int',
    output_sequence_length = 500)

text_vectorize_layer.adapt(train.map(lambda x, y: x["text"]))
```

## Create Models

Now, we will use our preparation to create models that will answer the following question.
> When detecting fake news, is it most effective to focus on only the title of the article, the full text of the article, or both?

This will be answered by creating three models: one that only learns based off the title of the article, one that only learns based off the text of the article, and one that uses both. Then, we'll compare the performance of the three models. We'll be using Keras functional API where multiple layers can be defined at once and combined. We'll begin by defining input layers for both types of input. You can read more about functional API [here](https://www.tensorflow.org/guide/keras/functional){:target="_blank"}.


```python
title_input = keras.Input(
    shape=(1,), # shape of the input (1 dimensional string)
    name="title", # same name as the dictionary key in the dataset
    dtype="string" # type of input (string)
)
text_input = keras.Input(
    shape=(1,),
    name = "text",
    dtype = "string"
)
```

### Model 1: Title Only

In our first model, we'll be adding various layers to our `model1_layer`, beginning with applying `title_vectorize_layer()` on the input created above. Then, we create an embedding layer with 10 dimensions, which analyzes the input with a vectorized representation of each word. You can learn more about embedding layers [here](https://medium.com/@kashyapkathrani/all-about-embeddings-829c8ff0bf5b){:target="_blank"}. Finally, we use familiar dropout pooling, and dense layers.


```python
model1_layer = title_vectorize_layer(title_input)
model1_layer = layers.Embedding(size_vocabulary, output_dim = 10, name = "embedding")(model1_layer)
model1_layer = layers.Dropout(0.2)(model1_layer)
model1_layer = layers.GlobalAveragePooling1D()(model1_layer)
model1_layer = layers.Dropout(0.2)(model1_layer)
model1_layer = layers.Dense(32, activation = 'relu')(model1_layer)
model1_layer = layers.Dense(2, name = "fake")(model1_layer) # 2 units to predict real or fake news
```

Create the model by specifying the inputs (the title data) and the outputs (the multiple layered functions created above).


```python
model1 = keras.Model(
    inputs = title_input,
    outputs = model1_layer
)

model1.summary()
```

    Model: "model"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     title (InputLayer)          [(None, 1)]               0         
                                                                     
     text_vectorization (TextVec  (None, 25)               0         
     torization)                                                     
                                                                     
     embedding (Embedding)       (None, 25, 10)            20000     
                                                                     
     dropout (Dropout)           (None, 25, 10)            0         
                                                                     
     global_average_pooling1d (G  (None, 10)               0         
     lobalAveragePooling1D)                                          
                                                                     
     dropout_1 (Dropout)         (None, 10)                0         
                                                                     
     dense (Dense)               (None, 32)                352       
                                                                     
     fake (Dense)                (None, 2)                 66        
                                                                     
    =================================================================
    Total params: 20,418
    Trainable params: 20,418
    Non-trainable params: 0
    _________________________________________________________________


We can examine the structure of our model using the `plot_model()` function.


```python
utils.plot_model(model1)
```




    
![HW4-output_34_0](/images/HW4-output_34_0.png)
    



We'll compile our model with the adam optimizer, compute loss using crossentropy, and display the accuracy of our model at each step.


```python
model1.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits = True),
              metrics = ['accuracy']
)
```

Finally, we will fit our model with 5 epochs on the training set, with the validation set to generate a validation accuracy.


```python
history1 = model1.fit(train, 
                      validation_data = val,
                      epochs = 5)
```

    Epoch 1/5


    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning:
    
    Input dict contained keys ['text'] which did not match any model input. They will be ignored by the model.
    


    17959/17959 [==============================] - 111s 6ms/step - loss: 0.1034 - accuracy: 0.9642 - val_loss: 0.0445 - val_accuracy: 0.9855
    Epoch 2/5
    17959/17959 [==============================] - 96s 5ms/step - loss: 0.0566 - accuracy: 0.9798 - val_loss: 0.0473 - val_accuracy: 0.9815
    Epoch 3/5
    17959/17959 [==============================] - 105s 6ms/step - loss: 0.0517 - accuracy: 0.9824 - val_loss: 0.0426 - val_accuracy: 0.9842
    Epoch 4/5
    17959/17959 [==============================] - 99s 5ms/step - loss: 0.0494 - accuracy: 0.9834 - val_loss: 0.0398 - val_accuracy: 0.9851
    Epoch 5/5
    17959/17959 [==============================] - 107s 6ms/step - loss: 0.0484 - accuracy: 0.9827 - val_loss: 0.0394 - val_accuracy: 0.9853


We'll plot the history of the training and validation accuracy across the 5 epochs. This uses the history object returned by the fit() method, which stores the "accuracy" and "val_accuracy" measurements.


```python
plt.plot(history1.history["accuracy"], label = "training") # plot the training accuracy
plt.plot(history1.history["val_accuracy"], label = "validation") # plot the validation accuracy
plt.gca().set(xlabel = "epoch", ylabel = "accuracy", title = "model1 accuracy")
plt.legend()

plt.show()
```


    
![HW4-output_40_0](/images/HW4-output_40_0.png)
    


Model 1 performed very well, scoring consistently **around 98% validation accuracy.** This is significantly better than the baseline model. There is no sign of overfitting, as the validation accuracy was always greater than the training accuracy.

### Model 2: Text Only

The second model is identical in every step apart from using the text data instead. This means using the `text_input` and `text_vectorize_layer()` function.


```python
model2_layer = text_vectorize_layer(text_input)
model2_layer = layers.Embedding(size_vocabulary, output_dim = 10, name = "embedding")(model2_layer)
model2_layer = layers.Dropout(0.2)(model2_layer)
model2_layer = layers.GlobalAveragePooling1D()(model2_layer)
model2_layer = layers.Dropout(0.2)(model2_layer)
model2_layer = layers.Dense(32, activation = 'relu')(model2_layer)
model2_layer = layers.Dense(2, name = "fake")(model2_layer)
```


```python
model2 = keras.Model(
    inputs = text_input,
    outputs = model2_layer
)

model2.summary()
```

    Model: "model_1"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     text (InputLayer)           [(None, 1)]               0         
                                                                     
     text_vectorization_1 (TextV  (None, 500)              0         
     ectorization)                                                   
                                                                     
     embedding (Embedding)       (None, 500, 10)           20000     
                                                                     
     dropout_2 (Dropout)         (None, 500, 10)           0         
                                                                     
     global_average_pooling1d_1   (None, 10)               0         
     (GlobalAveragePooling1D)                                        
                                                                     
     dropout_3 (Dropout)         (None, 10)                0         
                                                                     
     dense_1 (Dense)             (None, 32)                352       
                                                                     
     fake (Dense)                (None, 2)                 66        
                                                                     
    =================================================================
    Total params: 20,418
    Trainable params: 20,418
    Non-trainable params: 0
    _________________________________________________________________



```python
utils.plot_model(model2)
```




    
![HW4-output_46_0](/images/HW4-output_46_0.png)
    




```python
model2.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits = True),
              metrics = ['accuracy']
)
```


```python
history2 = model2.fit(train, 
                      validation_data = val,
                      epochs = 5)
```

    Epoch 1/5


    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['title'] which did not match any model input. They will be ignored by the model.
      inputs = self._flatten_to_reference_inputs(inputs)


    17959/17959 [==============================] - 73s 4ms/step - loss: 0.1710 - accuracy: 0.9341 - val_loss: 0.0745 - val_accuracy: 0.9817
    Epoch 2/5
    17959/17959 [==============================] - 71s 4ms/step - loss: 0.0846 - accuracy: 0.9717 - val_loss: 0.0784 - val_accuracy: 0.9753
    Epoch 3/5
    17959/17959 [==============================] - 71s 4ms/step - loss: 0.0708 - accuracy: 0.9764 - val_loss: 0.1054 - val_accuracy: 0.9552
    Epoch 4/5
    17959/17959 [==============================] - 71s 4ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.0381 - val_accuracy: 0.9911
    Epoch 5/5
    17959/17959 [==============================] - 71s 4ms/step - loss: 0.0559 - accuracy: 0.9807 - val_loss: 0.0308 - val_accuracy: 0.9911



```python
plt.plot(history2.history["accuracy"], label = "training") # plot the training accuracy
plt.plot(history2.history["val_accuracy"], label = "validation") # plot the validation accuracy
plt.gca().set(xlabel = "epoch", ylabel = "accuracy", title = "model1 accuracy")
plt.legend()

plt.show()
```


    
![HW4-output_49_0](/images/HW4-output_49_0.png)
    


Model 2 also performed very well, scoring **between 95% and 100% validation accuracy.** This is around the same as the previous model. There is no sign of overfitting, as the validation accuracy was always greater than the training accuracy.

### Model 3: Title and Text

Finally, our third model is almost identical to the last two, with the exception of using both title and text data. This means we'll use the `title_vectorize_layer()` and `text_vectorize_layer` functions on their respective inputs, before concatenating them with the `concatenate()` function and applying each successive layer on both inputs together.


```python
title_features = title_vectorize_layer(title_input)
text_features = text_vectorize_layer(text_input)

model3_layer = layers.concatenate([title_features, text_features], axis = 1)
model3_layer = layers.Embedding(size_vocabulary, output_dim = 10, name = "embedding")(model3_layer)
model3_layer = layers.Dropout(0.2)(model3_layer)
model3_layer = layers.GlobalAveragePooling1D()(model3_layer)
model3_layer = layers.Dropout(0.2)(model3_layer)
model3_layer = layers.Dense(32, activation = 'relu')(model3_layer)
model3_layer = layers.Dense(2, name = "fake")(model3_layer)
```


```python
model3 = keras.Model(
    inputs = [title_input, text_input],
    outputs = model3_layer
)

model3.summary()
```

    Model: "model_2"
    __________________________________________________________________________________________________
     Layer (type)                   Output Shape         Param #     Connected to                     
    ==================================================================================================
     title (InputLayer)             [(None, 1)]          0           []                               
                                                                                                      
     text (InputLayer)              [(None, 1)]          0           []                               
                                                                                                      
     text_vectorization (TextVector  (None, 25)          0           ['title[0][0]']                  
     ization)                                                                                         
                                                                                                      
     text_vectorization_1 (TextVect  (None, 500)         0           ['text[0][0]']                   
     orization)                                                                                       
                                                                                                      
     concatenate (Concatenate)      (None, 525)          0           ['text_vectorization[1][0]',     
                                                                      'text_vectorization_1[1][0]']   
                                                                                                      
     embedding (Embedding)          (None, 525, 10)      20000       ['concatenate[0][0]']            
                                                                                                      
     dropout_4 (Dropout)            (None, 525, 10)      0           ['embedding[0][0]']              
                                                                                                      
     global_average_pooling1d_2 (Gl  (None, 10)          0           ['dropout_4[0][0]']              
     obalAveragePooling1D)                                                                            
                                                                                                      
     dropout_5 (Dropout)            (None, 10)           0           ['global_average_pooling1d_2[0][0
                                                                     ]']                              
                                                                                                      
     dense_2 (Dense)                (None, 32)           352         ['dropout_5[0][0]']              
                                                                                                      
     fake (Dense)                   (None, 2)            66          ['dense_2[0][0]']                
                                                                                                      
    ==================================================================================================
    Total params: 20,418
    Trainable params: 20,418
    Non-trainable params: 0
    __________________________________________________________________________________________________


In the model diagram below, you can see how the inputs are initially separately, but later concatenated.


```python
utils.plot_model(model3)
```




    
![HW4-output_56_0](/images/HW4-output_56_0.png)
    




```python
model3.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits = True),
              metrics = ['accuracy']
)
```


```python
history3 = model3.fit(train, 
                      validation_data = val,
                      epochs = 5)
```

    Epoch 1/5
    17959/17959 [==============================] - 77s 4ms/step - loss: 0.1710 - accuracy: 0.9313 - val_loss: 0.0697 - val_accuracy: 0.9815
    Epoch 2/5
    17959/17959 [==============================] - 76s 4ms/step - loss: 0.0868 - accuracy: 0.9719 - val_loss: 0.0454 - val_accuracy: 0.9878
    Epoch 3/5
    17959/17959 [==============================] - 76s 4ms/step - loss: 0.0713 - accuracy: 0.9756 - val_loss: 0.0407 - val_accuracy: 0.9884
    Epoch 4/5
    17959/17959 [==============================] - 76s 4ms/step - loss: 0.0654 - accuracy: 0.9771 - val_loss: 0.0381 - val_accuracy: 0.9893
    Epoch 5/5
    17959/17959 [==============================] - 76s 4ms/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.0381 - val_accuracy: 0.9889



```python
plt.plot(history3.history["accuracy"], label = "training") # plot the training accuracy
plt.plot(history3.history["val_accuracy"], label = "validation") # plot the validation accuracy
plt.gca().set(xlabel = "epoch", ylabel = "accuracy", title = "model1 accuracy")
plt.legend()

plt.show()
```


    
![HW4-output_59_0](/images/HW4-output_59_0.png)
    


Model 3 also performed very well, scoring **around 98% validation accuracy.** This is around the same as the previous model. There is no sign of overfitting, as the validation accuracy was always greater than the training accuracy.

Overall, all 3 models performed very similarly, which indicates algorithms can use the title, text, or both to effectively detect fake news. If one had to be picked, the validation accuracy of model 1 was slightly more consistent than the other two, which implies that using only the title is the most effective indicator of fake news.

## Model Evaluation

For the purposes of evaluation, we will use model 1.


```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
df = pd.read_csv(train_url)
```


```python
test = make_dataset(df)
model1.evaluate(test)
```

    22449/22449 [==============================] - 70s 3ms/step - loss: 0.0360 - accuracy: 0.9870





    [0.03600744530558586, 0.9869927167892456]



Model 1 performed excellently, correctly differentiating between fake news and real news almost 99% of the time.

## Embedding Visualization

Finally, we will create a visualization that illustrates how the embedding layer works. We'll plot the weights (parameters) found in the embedding layer on a 2-dimensional axis. We transform the 10-dimensional vector representation in the layer to 2 dimensions using principal component analysis. 


```python
weights = model1.get_layer("embedding").get_weights()[0] # get the weights from the embedding layer

# get the 2000-sized vocabulary used when training model 1
vocab = title_vectorize_layer.get_vocabulary()

from sklearn.decomposition import PCA
pca = PCA(n_components = 2) # specify transformation to 2 dimensions
weights = pca.fit_transform(weights)

# create a dataframe that maps each vocab word to an x and y value
embedding_df = pd.DataFrame({
    'word' : vocab, 
    'x0'   : weights[:,0],
    'x1'   : weights[:,1]
})
```

We'll use a simple plotly call to create the scatter plot visualization.


```python
import plotly.express as px 
fig = px.scatter(embedding_df, # dataframe from which data is taken
                 x = 'x0', # column containing x values
                 y = 'x1', # columns containing y values
                 hover_name = 'word') # give each point a hover name corresponding to its word

fig.show()
```

{% include hw4_fig.html %}

The distribution of the words is quite flat; there are words that clearly contribute more to fake news and words that don't. Doing a quick observation reveals that country names such as "japan", "ukraine", "turkey", and "myanmar" are likely to be have more negative x-values. We can find "trump's" and "obama's" having positive x-values, along with descriptive words such as "racist", "disgusting", "brilliant", "angry", and "unhinged". It seems that words that contribute to fake news are found with more positive x-values, as they are words that may be used in more subjective statements, while country names (proper nouns) are more objective and have little to do with opinion, which is why they are found on the real news side (more negative x-values).
