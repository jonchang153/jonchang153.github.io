---
layout: post
title: Image Classification with TensorFlow
---

In this blog post, I'll demonstrate how to perform image classification with TensorFlow. I'll be classifying images of dogs and cats, and we'll see how our model can be improved with various tools such as transfer learning.

## Load Packages and Obtain Data

First, we will import some packages including keras, which will be used to build our models.


```python
import os
import tensorflow as tf
from tensorflow.keras import utils, layers, models, losses
import numpy as np
from matplotlib import pyplot as plt
```

We will pull our data from Google Cloud Storage and use keras functions to transform our data into a TensorFlow Dataset, containing 160x160 colored images in batches of 32. This will be split into training, validation, and testing sets.


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
    68608000/68606236 [==============================] - 1s 0us/step
    68616192/68606236 [==============================] - 1s 0us/step
    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.


Rapidly read in the data. See more at [https://www.tensorflow.org/guide/data_performance](https://www.tensorflow.org/guide/data_performance)


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

## Visualize Data

We'll examine our data by defining a function that displays two rows of 3 images, with cats in the first row and dogs in the second row.


```python
def visualize():
  plt.figure(figsize=(10,6))

  # indices for keeping track of which axis to plot on
  row1 = 1
  row2 = 1

  # iterate through one batch of image/label pairs in the training set
  for images, labels in train_dataset.take(1):

    # iterate through each of the 32 image/label pairs
    for i in range(len(labels)):

      # check if the image is a cat
      if labels[i] == 0:
        if row1 <= 3: # check that 3 cats haven't been plotted yet
          plt.subplot(2, 3, row1)
          plt.imshow(images[i].numpy().astype('uint8')) # plot the image
          plt.title('cat')
          plt.axis('off')
          row1 += 1

      # otherwise, if the image is a dog
      else:
        if row2 <= 3:
          plt.subplot(2, 3, row2+3)
          plt.imshow(images[i].numpy().astype('uint8'))
          plt.title('dog')
          plt.axis('off')
          row2 += 1
```


```python
visualize()
```


    
![HW3-output_11_0](/images/HW3-output_11_0.png)
    


## Check Label Frequencies

We can use the `as_numpy_iterator()` function to iterate through the training set. Use `unbatch()` to remove the batched shape of the dataset.


```python
labels_iterator = train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
```

Use this iterator to count the number of dogs and cats in the training set.


```python
count_cat = 0
count_dog = 0

# iterate through each element of the set and count hte number of cats and dogs
for label in labels_iterator:
  if label == 0:
    count_cat += 1
  else:
    count_dog += 1

print(count_cat, count_dog)
```

    1000 1000


Neither of the labels has a greater frequency than the other. If the baseline model were to arbitrarily guess one of the labels everytime, it would have an accuracy of 50%.

## Model 1

Now, we'll create our first model using the Sequential class from keras.models. This class stacks layers linearly. We'll use Conv2D layers to create our CNN, paired with pooling layers that reduce the size of each output. Then, we'll use a dropout layer to reduce the size of the training set, flatten each sample, and use a dense layer to reduce them into two numbers representing classification probabilities. You can read more about how CNNs work for classification here: [https://cnvrg.io/cnn-tensorflow/](https://cnvrg.io/cnn-tensorflow/)


```python
model1 = models.Sequential([
  # create a 2d convolutional layer with 32 kernels of size 3x3
  # we also specify input_shape here of our images to omit the use of an InputLayer
  layers.Conv2D(32, (3,3), activation='relu', input_shape=(160,160,3)),
  layers.MaxPooling2D((2,2)), # perform pooling with a 2x2 pool size
  layers.Conv2D(64, (3,3), activation='relu'),
  layers.MaxPooling2D((2,2)),
  layers.Dropout(0.2), # drop 20% of the number of input images
  layers.Flatten(), 
  layers.Dense(2)
])

model1.summary() # display parameter information about the model
```

    Model: "sequential"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d (Conv2D)             (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d (MaxPooling2D  (None, 79, 79, 32)       0         
     )                                                               
                                                                     
     conv2d_1 (Conv2D)           (None, 77, 77, 64)        18496     
                                                                     
     max_pooling2d_1 (MaxPooling  (None, 38, 38, 64)       0         
     2D)                                                             
                                                                     
     dropout (Dropout)           (None, 38, 38, 64)        0         
                                                                     
     flatten (Flatten)           (None, 92416)             0         
                                                                     
     dense (Dense)               (None, 2)                 184834    
                                                                     
    =================================================================
    Total params: 204,226
    Trainable params: 204,226
    Non-trainable params: 0
    _________________________________________________________________


We'll compile our model with the adam optimizer ([https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)), compute loss using crossentropy, and display the accuracy of our model at each step.


```python
model1.compile(optimizer = 'adam',
               loss = losses.SparseCategoricalCrossentropy(from_logits=True),
               # from_logits=True automatically normalizes output values with softmax
               metrics = ['accuracy'])
```

Finally, we will fit our model on the training set, with the validation set to generate a validation accuracy. Note the training and validation accuracies of the model after each epoch.


```python
history1 = model1.fit(train_dataset,
                      epochs = 20, # perform 20 rounds of training
                      validation_data = validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 17s 84ms/step - loss: 44.0236 - accuracy: 0.5390 - val_loss: 0.7197 - val_accuracy: 0.5173
    Epoch 2/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.6581 - accuracy: 0.6050 - val_loss: 0.7065 - val_accuracy: 0.5470
    Epoch 3/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.5678 - accuracy: 0.6920 - val_loss: 0.7898 - val_accuracy: 0.5483
    Epoch 4/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.4512 - accuracy: 0.7795 - val_loss: 0.8620 - val_accuracy: 0.5644
    Epoch 5/20
    63/63 [==============================] - 6s 82ms/step - loss: 0.3588 - accuracy: 0.8455 - val_loss: 0.8990 - val_accuracy: 0.5619
    Epoch 6/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.2755 - accuracy: 0.8865 - val_loss: 0.9559 - val_accuracy: 0.6027
    Epoch 7/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.2191 - accuracy: 0.9120 - val_loss: 1.2526 - val_accuracy: 0.5941
    Epoch 8/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.1912 - accuracy: 0.9370 - val_loss: 1.7101 - val_accuracy: 0.5681
    Epoch 9/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.1649 - accuracy: 0.9410 - val_loss: 1.6965 - val_accuracy: 0.5780
    Epoch 10/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.1313 - accuracy: 0.9490 - val_loss: 1.9298 - val_accuracy: 0.5879
    Epoch 11/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.1278 - accuracy: 0.9525 - val_loss: 1.9963 - val_accuracy: 0.6052
    Epoch 12/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.1256 - accuracy: 0.9610 - val_loss: 1.9270 - val_accuracy: 0.5817
    Epoch 13/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.1035 - accuracy: 0.9655 - val_loss: 2.2319 - val_accuracy: 0.5767
    Epoch 14/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.0903 - accuracy: 0.9695 - val_loss: 2.2204 - val_accuracy: 0.5965
    Epoch 15/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.0834 - accuracy: 0.9755 - val_loss: 2.9072 - val_accuracy: 0.5916
    Epoch 16/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.1251 - accuracy: 0.9595 - val_loss: 2.4726 - val_accuracy: 0.5829
    Epoch 17/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.0942 - accuracy: 0.9690 - val_loss: 2.7589 - val_accuracy: 0.5903
    Epoch 18/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.0899 - accuracy: 0.9750 - val_loss: 2.5755 - val_accuracy: 0.6015
    Epoch 19/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.0800 - accuracy: 0.9780 - val_loss: 2.4002 - val_accuracy: 0.6151
    Epoch 20/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.0671 - accuracy: 0.9790 - val_loss: 2.9650 - val_accuracy: 0.5866


We'll plot the history of the training and validation accuracy across the 20 epochs. This uses the history object returned by the fit() method, which stores the "accuracy" and "val_accuracy" data.


```python
plt.plot(history1.history["accuracy"], label = "training") # plot the training accuracy
plt.plot(history1.history["val_accuracy"], label = "validation") # plot the validation accuracy
plt.gca().set(xlabel = "epoch", ylabel = "accuracy", title = "model1 accuracy")
plt.legend()

plt.show()
```


    
![HW3-output_26_0](/images/HW3-output_26_0.png)
    


The accuracy of this model fluctuated **between 55% and 60%** during training. This is a noticeable improvement from the baseline model. Overfitting is very prominent, as the training accuracy increased to around 95% near the last few epochs, while the validation accuracy remained around 60%.

## Data Augmentation (Model 2)

In our second model, we will perform some data augmentation to help our model learn. For images, this means adding flipped or rotated copies of the same image in the training set. This  increases the diversity of the dataset and exposes the model to more variations of images.


```python
# take a single image from a single batch in the training set
for images, labels in train_dataset.take(1):
  example = images[0]
```

We'll demonstrate the effect of the RandomFlip and RandomRotation keras layers on a single image.


```python
fliph = layers.RandomFlip(mode='horizontal') # horizontal flip
flipv = layers.RandomFlip(mode='vertical') # vertical flip

# apply the flips
exampleh = fliph(example)
examplev = flipv(example)

# plot the original, horizontally flipped, and vertically flipped images on one figure.
fig, ax = plt.subplots(1,3)

ax[0].imshow(example.numpy().astype('uint8'))
ax[0].axis('off')

ax[1].imshow(exampleh.numpy().astype('uint8'))
ax[1].axis('off')

ax[2].imshow(examplev.numpy().astype('uint8'))
ax[2].axis('off')

fig.show()
```


    
![HW3-output_32_0](/images/HW3-output_32_0.png)
    



```python
# random rotation between -0.2 * 2pi and 0.2 * 2pi
rotate = layers.RandomRotation(factor = 0.2)

# apply the rotation to two examples
example1 = rotate(example)
example2 = rotate(example)

# plot the original and the two examples
fig, ax = plt.subplots(1,3)

ax[0].imshow(example.numpy().astype('uint8'))
ax[0].axis('off')

ax[1].imshow(example1.numpy().astype('uint8'))
ax[1].axis('off')

ax[2].imshow(example2.numpy().astype('uint8'))
ax[2].axis('off')

fig.show()
```


    
![HW3-output_33_0](/images/HW3-output_33_0.png)
    


Now, we will form the second model with the addition of these data augmentation layers as the first layers in the model. Everything else is identical from the first model, except that now the input shape is specified in the RandomFlip layer.


```python
model2 = models.Sequential([
  # RandomFlip layer that randomly flips images horizontally or vertically
  layers.RandomFlip('horizontal_and_vertical', input_shape = (160,160,3)),
  # RandomRotation layer that randomly rotates images between -0.2*2pi and 0.2*2pi
  layers.RandomRotation(factor = (0.2)),
  layers.Conv2D(32, (3,3), activation='relu'),
  layers.MaxPooling2D((2,2)),
  layers.Conv2D(64, (3,3), activation='relu'),
  layers.MaxPooling2D((2,2)),
  layers.Dropout(0.2),
  layers.Flatten(),
  layers.Dense(2)
])

model2.summary()
```

    Model: "sequential_2"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     random_flip_28 (RandomFlip)  (None, 160, 160, 3)      0         
                                                                     
     random_rotation_3 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     conv2d_4 (Conv2D)           (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d_4 (MaxPooling  (None, 79, 79, 32)       0         
     2D)                                                             
                                                                     
     conv2d_5 (Conv2D)           (None, 77, 77, 64)        18496     
                                                                     
     max_pooling2d_5 (MaxPooling  (None, 38, 38, 64)       0         
     2D)                                                             
                                                                     
     dropout_2 (Dropout)         (None, 38, 38, 64)        0         
                                                                     
     flatten_2 (Flatten)         (None, 92416)             0         
                                                                     
     dense_2 (Dense)             (None, 2)                 184834    
                                                                     
    =================================================================
    Total params: 204,226
    Trainable params: 204,226
    Non-trainable params: 0
    _________________________________________________________________



```python
model2.compile(optimizer = 'adam',
               loss = losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics = ['accuracy'])
```


```python
history2 = model2.fit(train_dataset,
                      epochs = 20,
                      validation_data = validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 7s 86ms/step - loss: 33.2969 - accuracy: 0.5115 - val_loss: 0.7072 - val_accuracy: 0.4963
    Epoch 2/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.7065 - accuracy: 0.5180 - val_loss: 0.7038 - val_accuracy: 0.4950
    Epoch 3/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6983 - accuracy: 0.5085 - val_loss: 0.6949 - val_accuracy: 0.5099
    Epoch 4/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6961 - accuracy: 0.5200 - val_loss: 0.7007 - val_accuracy: 0.5210
    Epoch 5/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6994 - accuracy: 0.4995 - val_loss: 0.7024 - val_accuracy: 0.5198
    Epoch 6/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6938 - accuracy: 0.5285 - val_loss: 0.6958 - val_accuracy: 0.5025
    Epoch 7/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6963 - accuracy: 0.5175 - val_loss: 0.6987 - val_accuracy: 0.5359
    Epoch 8/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6922 - accuracy: 0.5165 - val_loss: 0.6926 - val_accuracy: 0.5161
    Epoch 9/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6899 - accuracy: 0.5245 - val_loss: 0.6965 - val_accuracy: 0.5223
    Epoch 10/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6929 - accuracy: 0.5445 - val_loss: 0.6957 - val_accuracy: 0.5173
    Epoch 11/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6926 - accuracy: 0.5095 - val_loss: 0.6967 - val_accuracy: 0.5297
    Epoch 12/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6906 - accuracy: 0.5165 - val_loss: 0.6970 - val_accuracy: 0.5483
    Epoch 13/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6884 - accuracy: 0.5290 - val_loss: 0.6969 - val_accuracy: 0.5371
    Epoch 14/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6905 - accuracy: 0.5255 - val_loss: 0.6984 - val_accuracy: 0.5582
    Epoch 15/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6919 - accuracy: 0.5370 - val_loss: 0.6907 - val_accuracy: 0.5829
    Epoch 16/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6806 - accuracy: 0.5720 - val_loss: 0.6883 - val_accuracy: 0.5743
    Epoch 17/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6749 - accuracy: 0.5710 - val_loss: 0.6903 - val_accuracy: 0.5668
    Epoch 18/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6829 - accuracy: 0.5745 - val_loss: 0.6916 - val_accuracy: 0.5235
    Epoch 19/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.6798 - accuracy: 0.5830 - val_loss: 0.6856 - val_accuracy: 0.5644
    Epoch 20/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6752 - accuracy: 0.5795 - val_loss: 0.6857 - val_accuracy: 0.5767



```python
plt.plot(history2.history["accuracy"], label = "training")
plt.plot(history2.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy", title = "model2 accuracy")
plt.legend()

plt.show()
```


    
![HW3-output_38_0](/images/HW3-output_38_0.png)
    


The accuracy of this model fluctuated a lot during training, but increased to **between 55% and 60%**. This validation accuracy is about the same as the validation accuracy in model 1. There is much less overfitting than in model 1; as seen in the graph, although there were large fluctuations, the training accuracy was never consistently higher than the validation accuracy.

## Data Preprocessing (Model 3)

In our third model, we will add a preprocessing layer that will make training more efficient. In particular, we will use a function that normalizes the 0-255 RGB values of each image to between -1 and 1, which saves the model energy in scaling the weights to adjust to RGB values. This is slotted into the beginning of the sequential model.


```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```


```python
model3 = models.Sequential([
  preprocessor,
  layers.RandomFlip('horizontal_and_vertical'),
  layers.RandomRotation(factor = (0.2)),
  layers.Conv2D(32, (3,3), activation='relu'),
  layers.MaxPooling2D((2,2)),
  layers.Conv2D(64, (3,3), activation='relu'),
  layers.MaxPooling2D((2,2)),
  layers.Dropout(0.2),
  layers.Flatten(),
  layers.Dense(2)
])

model3.summary()
```

    Model: "sequential_5"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model (Functional)          (None, 160, 160, 3)       0         
                                                                     
     random_flip_24 (RandomFlip)  (None, 160, 160, 3)      0         
                                                                     
     random_rotation_11 (RandomR  (None, 160, 160, 3)      0         
     otation)                                                        
                                                                     
     conv2d_10 (Conv2D)          (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d_10 (MaxPoolin  (None, 79, 79, 32)       0         
     g2D)                                                            
                                                                     
     conv2d_11 (Conv2D)          (None, 77, 77, 64)        18496     
                                                                     
     max_pooling2d_11 (MaxPoolin  (None, 38, 38, 64)       0         
     g2D)                                                            
                                                                     
     dropout_7 (Dropout)         (None, 38, 38, 64)        0         
                                                                     
     flatten_5 (Flatten)         (None, 92416)             0         
                                                                     
     dense_7 (Dense)             (None, 2)                 184834    
                                                                     
    =================================================================
    Total params: 204,226
    Trainable params: 204,226
    Non-trainable params: 0
    _________________________________________________________________



```python
model3.compile(optimizer = 'adam',
               loss = losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics = ['accuracy'])
```


```python
history3 = model3.fit(train_dataset,
                      epochs = 20,
                      validation_data = validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 82ms/step - loss: 0.7396 - accuracy: 0.5425 - val_loss: 0.6570 - val_accuracy: 0.6349
    Epoch 2/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.6464 - accuracy: 0.6260 - val_loss: 0.6627 - val_accuracy: 0.5953
    Epoch 3/20
    63/63 [==============================] - 7s 114ms/step - loss: 0.6373 - accuracy: 0.6225 - val_loss: 0.6188 - val_accuracy: 0.6535
    Epoch 4/20
    63/63 [==============================] - 7s 96ms/step - loss: 0.6244 - accuracy: 0.6450 - val_loss: 0.6343 - val_accuracy: 0.5990
    Epoch 5/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.6077 - accuracy: 0.6690 - val_loss: 0.6099 - val_accuracy: 0.6671
    Epoch 6/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5884 - accuracy: 0.6855 - val_loss: 0.5850 - val_accuracy: 0.6795
    Epoch 7/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5750 - accuracy: 0.7020 - val_loss: 0.6060 - val_accuracy: 0.6807
    Epoch 8/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5771 - accuracy: 0.6905 - val_loss: 0.5797 - val_accuracy: 0.6943
    Epoch 9/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5672 - accuracy: 0.7105 - val_loss: 0.5899 - val_accuracy: 0.6708
    Epoch 10/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5595 - accuracy: 0.7120 - val_loss: 0.5723 - val_accuracy: 0.6832
    Epoch 11/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5503 - accuracy: 0.7210 - val_loss: 0.5900 - val_accuracy: 0.6869
    Epoch 12/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5654 - accuracy: 0.7050 - val_loss: 0.6067 - val_accuracy: 0.6906
    Epoch 13/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5664 - accuracy: 0.6995 - val_loss: 0.5922 - val_accuracy: 0.6733
    Epoch 14/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5608 - accuracy: 0.7080 - val_loss: 0.5675 - val_accuracy: 0.6931
    Epoch 15/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.5505 - accuracy: 0.7210 - val_loss: 0.5575 - val_accuracy: 0.7240
    Epoch 16/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5242 - accuracy: 0.7380 - val_loss: 0.5544 - val_accuracy: 0.7228
    Epoch 17/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5393 - accuracy: 0.7240 - val_loss: 0.5660 - val_accuracy: 0.7178
    Epoch 18/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5368 - accuracy: 0.7405 - val_loss: 0.5549 - val_accuracy: 0.7215
    Epoch 19/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5336 - accuracy: 0.7300 - val_loss: 0.5604 - val_accuracy: 0.7215
    Epoch 20/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.5224 - accuracy: 0.7445 - val_loss: 0.5483 - val_accuracy: 0.7277



```python
plt.plot(history3.history["accuracy"], label = "training")
plt.plot(history3.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy", title = "model3 accuracy")
plt.legend()

plt.show()
```


    
![HW3-output_46_0](/images/HW3-output_46_0.png)
    


The validation accuracy of this model steadily increased and **stabilized around 70%** during training. This is a significant accuracy improvement from model 1's accuracy. There is almost no overfitting; as seen in the graph, there is never a major difference between the training and validation accuracies.

## Transfer Learning (Model 4)

In our final model, we will use transfer learning to produce the most accurate model so far. This means using a pre-existing model that has been trained to efficiently perform image classification, and can be used as a base model for our task.


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5
    9412608/9406464 [==============================] - 0s 0us/step
    9420800/9406464 [==============================] - 0s 0us/step


This is slotted into our model, along with the previous preprocessing layer and data augmentation layers. There is no more need for convolutional layers, which are included in the imported layer. We also include a GlobalMaxPooling2D layer which performs pooling on the entire input shape, rather than specifying a pooling size.


```python
model4 = models.Sequential([
  preprocessor,
  layers.RandomFlip('horizontal_and_vertical'),
  layers.RandomRotation(factor = (0.2)),
  base_model_layer,
  layers.GlobalMaxPooling2D(),
  layers.Dense(2)
])

model4.summary()
```

    Model: "sequential"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model (Functional)          (None, 160, 160, 3)       0         
                                                                     
     random_flip (RandomFlip)    (None, 160, 160, 3)       0         
                                                                     
     random_rotation (RandomRota  (None, 160, 160, 3)      0         
     tion)                                                           
                                                                     
     model_1 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                     
     global_max_pooling2d (Globa  (None, 1280)             0         
     lMaxPooling2D)                                                  
                                                                     
     dense (Dense)               (None, 2)                 2562      
                                                                     
    =================================================================
    Total params: 2,260,546
    Trainable params: 2,562
    Non-trainable params: 2,257,984
    _________________________________________________________________


Notice that the base_model_layer adds more than 2 million parameters to the model.


```python
model4.compile(optimizer = 'adam',
               loss = losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics = ['accuracy'])
```


```python
history4 = model4.fit(train_dataset,
                      epochs = 20, # how many rounds of training to do
                      validation_data = validation_dataset) # see the performance of validation set after every epoch
```

    Epoch 1/20
    63/63 [==============================] - 49s 713ms/step - loss: 0.6814 - accuracy: 0.7865 - val_loss: 0.1432 - val_accuracy: 0.9493
    Epoch 2/20
    63/63 [==============================] - 43s 683ms/step - loss: 0.3662 - accuracy: 0.8820 - val_loss: 0.1099 - val_accuracy: 0.9604
    Epoch 3/20
    63/63 [==============================] - 43s 680ms/step - loss: 0.3834 - accuracy: 0.8825 - val_loss: 0.1317 - val_accuracy: 0.9542
    Epoch 4/20
    63/63 [==============================] - 43s 676ms/step - loss: 0.3246 - accuracy: 0.8920 - val_loss: 0.1175 - val_accuracy: 0.9579
    Epoch 5/20
    63/63 [==============================] - 43s 679ms/step - loss: 0.2757 - accuracy: 0.9070 - val_loss: 0.1216 - val_accuracy: 0.9530
    Epoch 6/20
    63/63 [==============================] - 43s 673ms/step - loss: 0.2669 - accuracy: 0.9070 - val_loss: 0.0851 - val_accuracy: 0.9715
    Epoch 7/20
    63/63 [==============================] - 43s 678ms/step - loss: 0.2694 - accuracy: 0.9165 - val_loss: 0.0806 - val_accuracy: 0.9691
    Epoch 8/20
    63/63 [==============================] - 43s 676ms/step - loss: 0.2616 - accuracy: 0.9110 - val_loss: 0.0850 - val_accuracy: 0.9678
    Epoch 9/20
    63/63 [==============================] - 42s 672ms/step - loss: 0.2590 - accuracy: 0.9135 - val_loss: 0.0842 - val_accuracy: 0.9715
    Epoch 10/20
    63/63 [==============================] - 42s 670ms/step - loss: 0.2476 - accuracy: 0.9145 - val_loss: 0.0953 - val_accuracy: 0.9678
    Epoch 11/20
    63/63 [==============================] - 43s 685ms/step - loss: 0.2012 - accuracy: 0.9325 - val_loss: 0.1139 - val_accuracy: 0.9691
    Epoch 12/20
    63/63 [==============================] - 44s 699ms/step - loss: 0.2122 - accuracy: 0.9250 - val_loss: 0.1023 - val_accuracy: 0.9666
    Epoch 13/20
    63/63 [==============================] - 44s 694ms/step - loss: 0.2106 - accuracy: 0.9245 - val_loss: 0.0947 - val_accuracy: 0.9715
    Epoch 14/20
    63/63 [==============================] - 44s 700ms/step - loss: 0.2199 - accuracy: 0.9265 - val_loss: 0.0859 - val_accuracy: 0.9703
    Epoch 15/20
    63/63 [==============================] - 45s 705ms/step - loss: 0.2006 - accuracy: 0.9275 - val_loss: 0.0794 - val_accuracy: 0.9740
    Epoch 16/20
    63/63 [==============================] - 44s 696ms/step - loss: 0.2170 - accuracy: 0.9270 - val_loss: 0.1234 - val_accuracy: 0.9604
    Epoch 17/20
    63/63 [==============================] - 45s 708ms/step - loss: 0.2455 - accuracy: 0.9195 - val_loss: 0.0894 - val_accuracy: 0.9653
    Epoch 18/20
    63/63 [==============================] - 44s 697ms/step - loss: 0.1987 - accuracy: 0.9300 - val_loss: 0.0943 - val_accuracy: 0.9678
    Epoch 19/20
    63/63 [==============================] - 44s 696ms/step - loss: 0.2213 - accuracy: 0.9280 - val_loss: 0.1189 - val_accuracy: 0.9666
    Epoch 20/20
    63/63 [==============================] - 44s 694ms/step - loss: 0.2456 - accuracy: 0.9220 - val_loss: 0.0886 - val_accuracy: 0.9703



```python
plt.plot(history4.history["accuracy"], label = "training")
plt.plot(history4.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy", title = "model3 accuracy")
plt.legend()

plt.show()
```


    
![HW3-output_56_0](/images/HW3-output_56_0.png)
    


The validation accuracy of this model was **consistently between 95% and 100%** during training. This is a very significant accuracy improvement from model 1's accuracy. Oddly, the validation accuracy was consistently higher than the training accuracy, which is not a sign of overfitting.

## Score on Test Data

Finally, we will evaluate our model on the unseen test data.


```python
model4.evaluate(test_dataset)
```

    6/6 [==============================] - 6s 842ms/step - loss: 0.0717 - accuracy: 0.9635





    [0.07169895619153976, 0.9635416865348816]



Our model achieved 96% accuracy, which is a significant improvement from a 50-50 baseline guess.
